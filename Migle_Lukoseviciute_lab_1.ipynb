{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "mount_file_id": "1VkzI8h69TXZWwvAX6OkSIhcsHx29s2X9",
   "authorship_tag": "ABX9TyPVQM5EHkNmli9LPynBhIdi",
   "include_colab_link": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/deer-in-haze/gilusis_mokymas/blob/main/Migle_Lukoseviciute_lab_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Importai"
  },
  {
   "metadata": {
    "id": "MTbhHkA_4Fd3",
    "outputId": "1f31373c-1371-457f-f1ba-a6feec415dd1",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "ExecuteTime": {
     "end_time": "2025-09-05T15:22:45.876147Z",
     "start_time": "2025-09-05T15:22:45.871054Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import ast\n",
    "import re\n",
    "import json\n",
    "from getpass import getpass\n",
    "\n",
    "import pandas as pd\n",
    "import google.generativeai as genai"
   ],
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Gemini API key"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-05T15:22:48.544204Z",
     "start_time": "2025-09-05T15:22:45.882826Z"
    }
   },
   "cell_type": "code",
   "source": [
    "os.environ[\"GEMINI_API_KEY\"] = getpass(\"Enter your API key: \")\n",
    "genai.configure(api_key=os.environ[\"GEMINI_API_KEY\"])"
   ],
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Modeliai"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-05T15:22:48.567754Z",
     "start_time": "2025-09-05T15:22:48.565668Z"
    }
   },
   "cell_type": "code",
   "source": [
    "models_to_test = [\n",
    "    \"gemini-2.5-pro\",\n",
    "    \"gemini-2.5-flash\",\n",
    "    \"gemini-2.5-flash-lite\",\n",
    "    \"gemma-3-1b-it\",\n",
    "    \"gemma-3-4b-it\",\n",
    "    \"gemma-3-27b-it\"\n",
    "]"
   ],
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Prisijungimo prie modeliÅ³ testas"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-05T15:23:02.382629Z",
     "start_time": "2025-09-05T15:22:48.597246Z"
    }
   },
   "cell_type": "code",
   "source": [
    "prompt = \"Hello!\"\n",
    "\n",
    "for model_id in models_to_test:\n",
    "    try:\n",
    "        response = genai.GenerativeModel(model_id).generate_content(prompt)\n",
    "        print(f\"\\n--- {model_id} ---\")\n",
    "        print(response.text)\n",
    "    except Exception as e:\n",
    "        print(f\"\\n--- {model_id} ---\")\n",
    "        print(\"Error:\", e)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- gemini-2.5-pro ---\n",
      "Hello there! How can I help you today?\n",
      "\n",
      "--- gemini-2.5-flash ---\n",
      "Hello there! How can I help you today?\n",
      "\n",
      "--- gemini-2.5-flash-lite ---\n",
      "Hello there! How can I help you today?\n",
      "\n",
      "--- gemma-3-1b-it ---\n",
      "Hello there! How's your day going so far? ðŸ˜Š \n",
      "\n",
      "Is there anything you'd like to chat about, or anything I can help you with?\n",
      "\n",
      "--- gemma-3-4b-it ---\n",
      "Hello there! Howâ€™s your day going so far? Is there anything I can help you with today? ðŸ˜Š\n",
      "\n",
      "--- gemma-3-27b-it ---\n",
      "Hello there! ðŸ‘‹ \n",
      "\n",
      "It's great to connect with you. How can I help you today? \n",
      "\n",
      "Just let me know what you're thinking, whether you have a question, want to brainstorm ideas, need some information, or just want to chat. I'm here and ready to assist! ðŸ˜Š\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "UÅ¾duotis"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-05T15:23:02.403952Z",
     "start_time": "2025-09-05T15:23:02.399293Z"
    }
   },
   "cell_type": "code",
   "source": [
    "prompt = \"\"\"\n",
    "Your task is to solve the following challenge. Follow every step carefully. The final answer must be returned in exact JSON format:\n",
    "{\n",
    "  \"fileReadSuccess\": <boolean>,\n",
    "  \"textSplitUpperBoundaryFound\": <boolean>,\n",
    "  \"textSplitBottomBoundaryFound\": <boolean>,\n",
    "  \"number_of_times_ghost_appears\": <number>,\n",
    "  \"number_of_times_shadow_appears\": <number>,\n",
    "  \"number_of_times_widger_appears\": <number>,\n",
    "  \"answer\": <number>\n",
    "}.\n",
    "Use the file located at this URL:\n",
    "https://www.gutenberg.org/cache/epub/98/pg98.txt\n",
    "From that text ignore everything before the line that starts with:\n",
    "*** START OF THE PROJECT GUTENBERG EBOOK A TALE OF TWO CITIES ***\n",
    "and ignore everything after the line that starts with:\n",
    "*** END OF THE PROJECT GUTENBERG EBOOK A TALE OF TWO CITIES ***\n",
    ".\n",
    "Within the cleaned text:\n",
    "Count how many times the exact word \"ghost\" (case-insensitive) appears.\n",
    "Count how many times the exact word \"shadow\" (case-insensitive) appears.\n",
    "Count how many times the exact word \"widger\" (case-insensitive) appears.\n",
    "Compute the following expression (answer):\n",
    "(number_of_times_ghost_appears Ã— 7) + (number_of_times_shadow_appears Ã— 13) + number_of_times_widger_appears\n",
    "Return only the result as JSON, no explanations.\n",
    "\"\"\"\n",
    "expectedJson = {\n",
    "  \"fileReadSuccess\": True,\n",
    "  \"textSplitUpperBoundaryFound\": True,\n",
    "  \"textSplitBottomBoundaryFound\": True,\n",
    "  \"number_of_times_ghost_appears\": 11,\n",
    "  \"number_of_times_shadow_appears\": 25,\n",
    "  \"number_of_times_widger_appears\": 0,\n",
    "  \"answer\": 402\n",
    "}\n",
    "\n",
    "requiredKeys = list(expectedJson.keys())"
   ],
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "PagalbinÄ—s funkcijos"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-05T15:23:02.423432Z",
     "start_time": "2025-09-05T15:23:02.415286Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def _extract_structured_obj(text: str):\n",
    "    if not text:\n",
    "        return None, \"empty response\"\n",
    "\n",
    "    s = text.strip()\n",
    "\n",
    "    m = re.search(r\"```(?:json|JSON)\\s*\\n(.*?)```\", s, flags=re.DOTALL)\n",
    "    if not m:\n",
    "        m = re.search(r\"```[\\w+-]*\\s*\\n(.*?)```\", s, flags=re.DOTALL)\n",
    "    candidate = m.group(1).strip() if m else s\n",
    "\n",
    "    try:\n",
    "        obj = json.loads(candidate)\n",
    "        if isinstance(obj, dict):\n",
    "            return obj, None\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    m = re.search(r\"\\{.*?\\}\", candidate, flags=re.DOTALL)\n",
    "    if m:\n",
    "        block = m.group(0)\n",
    "        try:\n",
    "            obj = json.loads(block)\n",
    "            if isinstance(obj, dict):\n",
    "                return obj, None\n",
    "        except Exception:\n",
    "            try:\n",
    "                obj = ast.literal_eval(block)\n",
    "                if isinstance(obj, dict):\n",
    "                    return obj, None\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "    return None, \"could not extract a JSON/Python dict payload\"\n",
    "\n",
    "def _normalize_for_compare(value, expected):\n",
    "\n",
    "    if isinstance(expected, bool):\n",
    "        if isinstance(value, str):\n",
    "            v = value.strip().lower()\n",
    "            if v in (\"true\", \"false\"):\n",
    "                return v == \"true\"\n",
    "        return bool(value) if isinstance(value, (bool, int)) else value\n",
    "    if isinstance(expected, int):\n",
    "        if isinstance(value, str) and re.fullmatch(r\"-?\\d+\", value.strip()):\n",
    "            return int(value.strip())\n",
    "    if isinstance(expected, float):\n",
    "        if isinstance(value, (int, float)):\n",
    "            return float(value)\n",
    "        if isinstance(value, str) and re.fullmatch(r\"-?\\d+(?:\\.\\d+)?\", value.strip()):\n",
    "            return float(value.strip())\n",
    "    return value\n",
    "\n",
    "def assess_model_response_flat(model_id, model_output, expected_data, required_keys=None):\n",
    "    if required_keys is None:\n",
    "        required_keys = list(expected_data.keys())\n",
    "\n",
    "    obj, reason = _extract_structured_obj(model_output)\n",
    "    row = {\"model\": model_id}\n",
    "\n",
    "    if obj is None:\n",
    "        row.update({k: None for k in required_keys})\n",
    "        row[\"PASS\"] = False\n",
    "        row[\"reason\"] = f\"Could not extract JSON: {reason}\"\n",
    "        return row\n",
    "\n",
    "    mismatches = []\n",
    "    for k in required_keys:\n",
    "        got_raw = obj.get(k, None)\n",
    "        expected = expected_data[k]\n",
    "        got_norm = _normalize_for_compare(got_raw, expected)\n",
    "        match = (got_norm == expected)\n",
    "        row[k] = got_raw\n",
    "        if not match:\n",
    "            mismatches.append(f\"{k}: expected {expected!r}, got {got_raw!r}\")\n",
    "\n",
    "    row[\"PASS\"] = len(mismatches) == 0\n",
    "    row[\"reason\"] = \"; \".join(mismatches) if mismatches else \"All match\"\n",
    "    return row"
   ],
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Generavimas su visais modeliais"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-05T15:24:13.555483Z",
     "start_time": "2025-09-05T15:23:02.431099Z"
    }
   },
   "cell_type": "code",
   "source": [
    "rows = []\n",
    "\n",
    "for model_id in models_to_test:\n",
    "    try:\n",
    "        response = genai.GenerativeModel(model_id).generate_content(prompt)\n",
    "        raw = getattr(response, \"text\", \"\") or \"\"\n",
    "        row = assess_model_response_flat(model_id, raw, expectedJson, required_keys=requiredKeys)\n",
    "        rows.append(row)\n",
    "    except Exception as e:\n",
    "        rows.append({\"model\": model_id, \"PASS\": False, \"reason\": str(e)})\n",
    "\n",
    "expected_row = {\"model\": \"EXPECTED\"}\n",
    "for k, v in expectedJson.items():\n",
    "    expected_row[k] = v\n",
    "expected_row[\"PASS\"] = True\n",
    "expected_row[\"reason\"] = \"Ground truth\"\n",
    "rows.append(expected_row)\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "\n",
    "df.to_csv(\"rezultatai.csv\", index=False)"
   ],
   "outputs": [],
   "execution_count": 34
  }
 ]
}
