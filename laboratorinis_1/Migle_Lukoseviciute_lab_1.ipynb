{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "mount_file_id": "1VkzI8h69TXZWwvAX6OkSIhcsHx29s2X9",
   "authorship_tag": "ABX9TyPVQM5EHkNmli9LPynBhIdi",
   "include_colab_link": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/deer-in-haze/gilusis_mokymas/blob/main/Migle_Lukoseviciute_lab_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Importai"
  },
  {
   "metadata": {
    "id": "MTbhHkA_4Fd3",
    "outputId": "1f31373c-1371-457f-f1ba-a6feec415dd1",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "ExecuteTime": {
     "end_time": "2025-09-05T16:12:02.468104Z",
     "start_time": "2025-09-05T16:12:02.458378Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import ast\n",
    "import re\n",
    "import json\n",
    "from google.generativeai.types import GenerationConfig\n",
    "from getpass import getpass\n",
    "\n",
    "import pandas as pd\n",
    "import google.generativeai as genai"
   ],
   "outputs": [],
   "execution_count": 45
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Gemini API key"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-05T15:22:48.544204Z",
     "start_time": "2025-09-05T15:22:45.882826Z"
    }
   },
   "cell_type": "code",
   "source": [
    "os.environ[\"GEMINI_API_KEY\"] = getpass(\"Enter your API key: \")\n",
    "genai.configure(api_key=os.environ[\"GEMINI_API_KEY\"])"
   ],
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Modeliai"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-05T15:22:48.567754Z",
     "start_time": "2025-09-05T15:22:48.565668Z"
    }
   },
   "cell_type": "code",
   "source": [
    "models_to_test = [\n",
    "    \"gemini-2.5-pro\",\n",
    "    \"gemini-2.5-flash\",\n",
    "    \"gemini-2.5-flash-lite\",\n",
    "    \"gemma-3-1b-it\",\n",
    "    \"gemma-3-4b-it\",\n",
    "    \"gemma-3-27b-it\"\n",
    "]"
   ],
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Prisijungimo prie modelių testas"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-05T16:19:36.573837Z",
     "start_time": "2025-09-05T16:19:12.142236Z"
    }
   },
   "cell_type": "code",
   "source": [
    "prompt = \"Write a 4 line poem about Vilnius.\"\n",
    "\n",
    "for model_id in models_to_test:\n",
    "    try:\n",
    "        response = genai.GenerativeModel(model_id).generate_content(prompt, generation_config=GenerationConfig(temperature=0))\n",
    "        print(f\"\\n--- {model_id} ---\")\n",
    "        print(response.text)\n",
    "    except Exception as e:\n",
    "        print(f\"\\n--- {model_id} ---\")\n",
    "        print(\"Error:\", e)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- gemini-2.5-pro ---\n",
      "Where cobbled alleys gently wind,\n",
      "And baroque angels watch mankind,\n",
      "A city dreamed upon a hill,\n",
      "Whose quiet beauty holds you still.\n",
      "\n",
      "--- gemini-2.5-flash ---\n",
      "Baroque spires, a city of grace,\n",
      "Cobbled lanes, history's embrace.\n",
      "From Gediminas' hill, a timeless view,\n",
      "Old Vilnius whispers, ever new.\n",
      "\n",
      "--- gemini-2.5-flash-lite ---\n",
      "Cobblestone streets whisper tales of old,\n",
      "Gothic spires, a story to unfold.\n",
      "Vilnius breathes history, vibrant and grand,\n",
      "A Baltic gem, held in time's gentle hand.\n",
      "\n",
      "--- gemma-3-1b-it ---\n",
      "In Vilnius' heart, a history sleeps,\n",
      "Of cobbled streets and ancient keeps.\n",
      "A blend of cultures, a vibrant hue,\n",
      "Where Baltic breezes softly accrue.\n",
      "\n",
      "--- gemma-3-4b-it ---\n",
      "In Vilnius' streets, a history sleeps,\n",
      "With Gothic spires and secrets deep.\n",
      "A charming city, old and bright,\n",
      "Bathed in Baltic’s golden light.\n",
      "\n",
      "--- gemma-3-27b-it ---\n",
      "Where Neris flows, a history deep,\n",
      "Vilnius unfolds, secrets to keep.\n",
      "Baroque whispers in cobbled stone,\n",
      "A Baltic beauty, uniquely shown.\n"
     ]
    }
   ],
   "execution_count": 57
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-05T16:20:58.187020Z",
     "start_time": "2025-09-05T16:20:37.990841Z"
    }
   },
   "cell_type": "code",
   "source": [
    "prompt = \"Write a 4 line poem about Vilnius.\"\n",
    "\n",
    "for model_id in models_to_test:\n",
    "    try:\n",
    "        response = genai.GenerativeModel(model_id).generate_content(prompt, generation_config=GenerationConfig(temperature=1))\n",
    "        print(f\"\\n--- {model_id} ---\")\n",
    "        print(response.text)\n",
    "    except Exception as e:\n",
    "        print(f\"\\n--- {model_id} ---\")\n",
    "        print(\"Error:\", e)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- gemini-2.5-pro ---\n",
      "A sea of red roofs, soft and deep,\n",
      "While ancient cobblestone secrets keep.\n",
      "Baroque spires reach for sunlit skies,\n",
      "Where quiet, gentle history lies.\n",
      "\n",
      "--- gemini-2.5-flash ---\n",
      "Red roofs tumble, Baroque spires gleam,\n",
      "A cobblestone city, an ancient dream.\n",
      "By Neris' gentle, winding stream,\n",
      "Vilnius, a timeless, vibrant scene.\n",
      "\n",
      "--- gemini-2.5-flash-lite ---\n",
      "Cobblestone streets whisper tales of old,\n",
      "Gothic spires reach for skies of gold.\n",
      "Vilnius dreams, a city reborn,\n",
      "Where history's charm greets every morn.\n",
      "\n",
      "--- gemma-3-1b-it ---\n",
      "In Vilnius' heart, a history sleeps,\n",
      "Of cobbled streets and ancient keeps.\n",
      "A blend of cultures, a vibrant hue,\n",
      "Where Baltic breezes softly accrue.\n",
      "\n",
      "--- gemma-3-4b-it ---\n",
      "In Vilnius' streets, a history sleeps,\n",
      "With Gothic spires and secrets deep.\n",
      "A charming city, old and bright,\n",
      "Bathed in Baltic’s golden light.\n",
      "\n",
      "--- gemma-3-27b-it ---\n",
      "Where Neris flows, a history deep,\n",
      "Vilnius unfolds, secrets to keep.\n",
      "Baroque whispers in cobbled stone,\n",
      "A Baltic beauty, uniquely shown.\n"
     ]
    }
   ],
   "execution_count": 58
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-05T16:21:54.774042Z",
     "start_time": "2025-09-05T16:21:33.707830Z"
    }
   },
   "cell_type": "code",
   "source": [
    "prompt = \"Write a 4 line poem about Vilnius.\"\n",
    "\n",
    "for model_id in models_to_test:\n",
    "    try:\n",
    "        response = genai.GenerativeModel(model_id).generate_content(prompt, generation_config=GenerationConfig(temperature=2))\n",
    "        print(f\"\\n--- {model_id} ---\")\n",
    "        print(response.text)\n",
    "    except Exception as e:\n",
    "        print(f\"\\n--- {model_id} ---\")\n",
    "        print(\"Error:\", e)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- gemini-2.5-pro ---\n",
      "Where ancient cobblestones descend,\n",
      "And amber spires meet gentle skies,\n",
      "An iron wolf’s old dream ascends,\n",
      "In every courtyard’s soft surprise.\n",
      "\n",
      "--- gemini-2.5-flash ---\n",
      "From cobbled lanes to spires in the sky,\n",
      "Old Vilnius breathes where ancient legends lie.\n",
      "Red rooftops glow, a Baroque embrace,\n",
      "Timeless beauty fills this sacred place.\n",
      "\n",
      "--- gemini-2.5-flash-lite ---\n",
      "Old town whispers, steeples climb,\n",
      "Gothic dreams in cobbled time.\n",
      "Gediminas's Tower stands so tall,\n",
      "Vilnius, spirit enchants all.\n",
      "\n",
      "--- gemma-3-1b-it ---\n",
      "In Vilnius' heart, a history sleeps,\n",
      "Of cobbled streets and ancient keeps.\n",
      "A blend of cultures, a vibrant hue,\n",
      "Where Baltic breezes softly accrue.\n",
      "\n",
      "--- gemma-3-4b-it ---\n",
      "In Vilnius' streets, a history sleeps,\n",
      "With Gothic spires and secrets deep.\n",
      "A charming city, old and bright,\n",
      "Bathed in Baltic’s golden light.\n",
      "\n",
      "--- gemma-3-27b-it ---\n",
      "Where Neris flows, a history deep,\n",
      "Vilnius stands, secrets to keep.\n",
      "Baroque whispers in cobbled stone,\n",
      "A Baltic beauty, uniquely grown.\n"
     ]
    }
   ],
   "execution_count": 59
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Užduotis"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-05T15:23:02.403952Z",
     "start_time": "2025-09-05T15:23:02.399293Z"
    }
   },
   "cell_type": "code",
   "source": [
    "prompt = \"\"\"\n",
    "Your task is to solve the following challenge. Follow every step carefully. The final answer must be returned in exact JSON format:\n",
    "{\n",
    "  \"fileReadSuccess\": <boolean>,\n",
    "  \"textSplitUpperBoundaryFound\": <boolean>,\n",
    "  \"textSplitBottomBoundaryFound\": <boolean>,\n",
    "  \"number_of_times_ghost_appears\": <number>,\n",
    "  \"number_of_times_shadow_appears\": <number>,\n",
    "  \"number_of_times_widger_appears\": <number>,\n",
    "  \"answer\": <number>\n",
    "}.\n",
    "Use the file located at this URL:\n",
    "https://www.gutenberg.org/cache/epub/98/pg98.txt\n",
    "From that text ignore everything before the line that starts with:\n",
    "*** START OF THE PROJECT GUTENBERG EBOOK A TALE OF TWO CITIES ***\n",
    "and ignore everything after the line that starts with:\n",
    "*** END OF THE PROJECT GUTENBERG EBOOK A TALE OF TWO CITIES ***\n",
    ".\n",
    "Within the cleaned text:\n",
    "Count how many times the exact word \"ghost\" (case-insensitive) appears.\n",
    "Count how many times the exact word \"shadow\" (case-insensitive) appears.\n",
    "Count how many times the exact word \"widger\" (case-insensitive) appears.\n",
    "Compute the following expression (answer):\n",
    "(number_of_times_ghost_appears × 7) + (number_of_times_shadow_appears × 13) + number_of_times_widger_appears\n",
    "Return only the result as JSON, no explanations.\n",
    "\"\"\"\n",
    "expectedJson = {\n",
    "  \"fileReadSuccess\": True,\n",
    "  \"textSplitUpperBoundaryFound\": True,\n",
    "  \"textSplitBottomBoundaryFound\": True,\n",
    "  \"number_of_times_ghost_appears\": 11,\n",
    "  \"number_of_times_shadow_appears\": 25,\n",
    "  \"number_of_times_widger_appears\": 0,\n",
    "  \"answer\": 402\n",
    "}\n",
    "\n",
    "requiredKeys = list(expectedJson.keys())"
   ],
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Pagalbinės funkcijos"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-05T15:23:02.423432Z",
     "start_time": "2025-09-05T15:23:02.415286Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def _extract_structured_obj(text: str):\n",
    "    if not text:\n",
    "        return None, \"empty response\"\n",
    "\n",
    "    s = text.strip()\n",
    "\n",
    "    m = re.search(r\"```(?:json|JSON)\\s*\\n(.*?)```\", s, flags=re.DOTALL)\n",
    "    if not m:\n",
    "        m = re.search(r\"```[\\w+-]*\\s*\\n(.*?)```\", s, flags=re.DOTALL)\n",
    "    candidate = m.group(1).strip() if m else s\n",
    "\n",
    "    try:\n",
    "        obj = json.loads(candidate)\n",
    "        if isinstance(obj, dict):\n",
    "            return obj, None\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    m = re.search(r\"\\{.*?\\}\", candidate, flags=re.DOTALL)\n",
    "    if m:\n",
    "        block = m.group(0)\n",
    "        try:\n",
    "            obj = json.loads(block)\n",
    "            if isinstance(obj, dict):\n",
    "                return obj, None\n",
    "        except Exception:\n",
    "            try:\n",
    "                obj = ast.literal_eval(block)\n",
    "                if isinstance(obj, dict):\n",
    "                    return obj, None\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "    return None, \"could not extract a JSON/Python dict payload\"\n",
    "\n",
    "def _normalize_for_compare(value, expected):\n",
    "\n",
    "    if isinstance(expected, bool):\n",
    "        if isinstance(value, str):\n",
    "            v = value.strip().lower()\n",
    "            if v in (\"true\", \"false\"):\n",
    "                return v == \"true\"\n",
    "        return bool(value) if isinstance(value, (bool, int)) else value\n",
    "    if isinstance(expected, int):\n",
    "        if isinstance(value, str) and re.fullmatch(r\"-?\\d+\", value.strip()):\n",
    "            return int(value.strip())\n",
    "    if isinstance(expected, float):\n",
    "        if isinstance(value, (int, float)):\n",
    "            return float(value)\n",
    "        if isinstance(value, str) and re.fullmatch(r\"-?\\d+(?:\\.\\d+)?\", value.strip()):\n",
    "            return float(value.strip())\n",
    "    return value\n",
    "\n",
    "def assess_model_response_flat(model_id, model_output, expected_data, required_keys=None):\n",
    "    if required_keys is None:\n",
    "        required_keys = list(expected_data.keys())\n",
    "\n",
    "    obj, reason = _extract_structured_obj(model_output)\n",
    "    row = {\"model\": model_id}\n",
    "\n",
    "    if obj is None:\n",
    "        row.update({k: None for k in required_keys})\n",
    "        row[\"PASS\"] = False\n",
    "        row[\"reason\"] = f\"Could not extract JSON: {reason}\"\n",
    "        return row\n",
    "\n",
    "    mismatches = []\n",
    "    for k in required_keys:\n",
    "        got_raw = obj.get(k, None)\n",
    "        expected = expected_data[k]\n",
    "        got_norm = _normalize_for_compare(got_raw, expected)\n",
    "        match = (got_norm == expected)\n",
    "        row[k] = got_raw\n",
    "        if not match:\n",
    "            mismatches.append(f\"{k}: expected {expected!r}, got {got_raw!r}\")\n",
    "\n",
    "    row[\"PASS\"] = len(mismatches) == 0\n",
    "    row[\"reason\"] = \"; \".join(mismatches) if mismatches else \"All match\"\n",
    "    return row"
   ],
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Generavimas su visais modeliais"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-05T16:10:16.853313Z",
     "start_time": "2025-09-05T16:08:48.325856Z"
    }
   },
   "cell_type": "code",
   "source": [
    "rows = []\n",
    "raw_sections = []\n",
    "\n",
    "for model_id in models_to_test:\n",
    "    try:\n",
    "        response = genai.GenerativeModel(model_id).generate_content(\n",
    "            prompt,\n",
    "            generation_config=GenerationConfig(temperature=2),\n",
    "        )\n",
    "        raw = getattr(response, \"text\", \"\") or \"\"\n",
    "\n",
    "        section = f\"\\n\\n===== {model_id.upper()} =====\\n{raw.strip() or '[no text returned]'}\\n\"\n",
    "        raw_sections.append(section)\n",
    "\n",
    "        row = assess_model_response_flat(model_id, raw, expectedJson, required_keys=requiredKeys)\n",
    "        rows.append(row)\n",
    "    except Exception as e:\n",
    "        err_msg = f\"ERROR: {e}\"\n",
    "        raw_sections.append(f\"\\n\\n===== {model_id.upper()} =====\\n{err_msg}\\n\")\n",
    "        rows.append({\"model\": model_id, \"PASS\": False, \"reason\": str(e)})\n",
    "\n",
    "expected_row = {\"model\": \"Actual\"}\n",
    "for k, v in expectedJson.items():\n",
    "    expected_row[k] = v\n",
    "expected_row[\"PASS\"] = True\n",
    "expected_row[\"reason\"] = \"Manually calculated results\"\n",
    "rows.append(expected_row)\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "df.to_csv(\"rezultatai_2_temp.csv\", index=False)\n",
    "\n",
    "with open(\"neapdoroti_atsakymai_2_temp.txt\", \"w\") as f:\n",
    "    f.writelines(raw_sections)\n"
   ],
   "outputs": [],
   "execution_count": 44
  }
 ]
}
